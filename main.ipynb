{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Universidad del Valle de Guatemala\n",
    "HT2 2\n",
    "Mineria de datos\n",
    "Roberto Rios, 20979\n",
    "Javier Valle, 20159\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.cluster as cluster\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "# Cargando el csv con pandas.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "# Imprimendo todas las columnas.\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paqui\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\paqui\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hopkins statistic: 0.9999998604735623\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "# dejar unicamente las columnas numericas\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df2 = df[numerical_cols]\n",
    "df2 = df2.drop('id',axis=1)\n",
    "\n",
    "def hopkins(X: pd.DataFrame):\n",
    "    m, d = X.shape\n",
    "    # aplicar un modelo para encontrar al k-nn de los puntos en el dataset\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X)\n",
    "    \n",
    "    # data random para comparar\n",
    "    rand_X = np.random.uniform(low=X.min(), high=X.max(), size=(m, d))\n",
    "\n",
    "    # hayar kneighbors\n",
    "    rand_nbrs_dist, _ = nbrs.kneighbors(rand_X)\n",
    "    data_nbrs_dist, _ = nbrs.kneighbors(normalize(X))\n",
    "\n",
    "    \n",
    "    # obtener el hopkins statistic\n",
    "    hopkins = sum(rand_nbrs_dist) / (sum(rand_nbrs_dist) + sum(data_nbrs_dist))\n",
    "\n",
    "    return hopkins[0]\n",
    "\n",
    "\n",
    "# compute the Hopkins statistic\n",
    "hopkins_statistic = hopkins(df2)\n",
    "\n",
    "print(\"Hopkins statistic:\", hopkins_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pyclustertend import vat\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "cols = ['budget', 'genres', 'productionCompany',\n",
    "       'productionCompanyCountry', 'productionCountry', 'revenue', 'runtime',\n",
    "       'video', 'director', 'actors', 'actorsPopularity', 'actorsCharacter',\n",
    "       'originalTitle', 'title', 'originalLanguage', 'popularity',\n",
    "       'releaseDate', 'voteAvg', 'voteCount', 'genresAmount',\n",
    "       'productionCoAmount', 'productionCountriesAmount', 'actorsAmount',\n",
    "       'castWomenAmount', 'castMenAmount']\n",
    "\n",
    "\n",
    "# convert the categorical features in the dataset to numerical \n",
    "df_encoded = df.drop('id',axis=1)\n",
    "df_encoded = df.drop('homePage',axis=1)\n",
    "\n",
    "\n",
    "df_encoded = pd.get_dummies(df_encoded, columns = cols)\n",
    "df_encoded = df_encoded.values # numpy array\n",
    "\n",
    "print(df_encoded)\n",
    "\n",
    "# obtain vat matrix\n",
    "vat(df_encoded, figure_size=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Primera gráfica de codo.\n",
    "\n",
    "# Creando un arreglo con los datos de las columnas a utilizar.\n",
    "X = np.array(df[[\"voteAvg\", \"voteCount\", \"popularity\", \"budget\", \"revenue\", \"runtime\"]])\n",
    "\n",
    "\n",
    "# Ejercicio 3: Calcular el número adecuado de grupos a formar.\n",
    "\n",
    "clusters = range(1, 11)\n",
    "wcss = []\n",
    "\n",
    "# Cálculo de la varianza dentro del cluster.\n",
    "for k in clusters:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficando la varianza dentro del cluster.\n",
    "pl.plot(clusters, wcss)\n",
    "pl.title('Gráfica de codo')\n",
    "pl.xlabel('Número de clusters')\n",
    "pl.ylabel('Varianza dentro del cluster')\n",
    "pl.show()\n",
    "\n",
    "# Segunda gráfica de codo.\n",
    "\n",
    "# Creando un arreglo con los datos de las columnas a utilizar.\n",
    "Y = np.array(df[[\"genresAmount\",\"voteAvg\", \"genresAmount\"]])\n",
    "\n",
    "clusters = range(1, 11)\n",
    "wcss = []\n",
    "\n",
    "# Cálculo de la varianza dentro del cluster.\n",
    "for k in clusters:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(Y)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficando la varianza dentro del cluster.\n",
    "pl.plot(clusters, wcss)\n",
    "pl.title('Gráfica 2 de codo')\n",
    "pl.xlabel('Número de clusters')\n",
    "pl.ylabel('Varianza dentro del cluster')\n",
    "pl.show()\n",
    "\n",
    "# Tercera gráfica de codo.\n",
    "\n",
    "# Creando un arreglo con los datos de las columnas a utilizar.\n",
    "Z = np.array(df[[\"productionCoAmount\", \"productionCountriesAmount\", \"castWomenAmount\", \"castMenAmount\"]])\n",
    "\n",
    "clusters = range(1, 11)\n",
    "wcss = []\n",
    "\n",
    "# Cálculo de la varianza dentro del cluster.\n",
    "for k in clusters:\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(Y)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficando la varianza dentro del cluster.\n",
    "pl.plot(clusters, wcss)\n",
    "pl.title('Gráfica 3 de codo')\n",
    "pl.xlabel('Número de clusters')\n",
    "pl.ylabel('Varianza dentro del cluster')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Ejercicio 4: Usar los algoritmos k-medias y cluster jerárquico para agrupar los datos.\n",
    "\n",
    "# Creando el modelo de k-medias. Cluster X.\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Calculando el centroide de cada cluster.\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "cluster1 = kmeans.predict(X)\n",
    "\n",
    "# Graficando los clusters.\n",
    "pl.scatter(X[cluster1 == 0, 0], X[cluster1 == 0, 1],s=100,c='red', label = \"Cluster 1\")\n",
    "pl.scatter(X[cluster1 == 1, 0], X[cluster1 == 1, 1],s=100,c='blue', label = \"Cluster 1\")\n",
    "pl.scatter(X[cluster1 == 2, 0], X[cluster1 == 2, 1],s=100,c='green', label = \"Cluster 1\")\n",
    "pl.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s=300, c=\"yellow\",marker=\"*\", label=\"Centroides\")\n",
    "pl.title(\"Grupo 1\")\n",
    "pl.xlabel(\"Cluster1.length\")\n",
    "pl.ylabel(\"Cluster1.width\")\n",
    "pl.legend()\n",
    "\n",
    "# Creando el modelo de k-medias. Cluster Y.\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(Y)\n",
    "\n",
    "# Calculando el centroide de cada cluster.\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "\n",
    "cluster2 = kmeans.predict(Y)\n",
    "\n",
    "\n",
    "# Graficando los clusters.\n",
    "pl.scatter(Y[cluster2 == 0, 0], Y[cluster2 == 0, 1],s=100,c='red', label = \"Cluster 2\")\n",
    "pl.scatter(Y[cluster2 == 1, 0], Y[cluster2 == 1, 1],s=100,c='blue', label = \"Cluster 2\")\n",
    "pl.scatter(Y[cluster2 == 2, 0], Y[cluster2 == 2, 1],s=100,c='green', label = \"Cluster 2\")\n",
    "pl.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s=300, c=\"yellow\",marker=\"*\", label=\"Centroides\")\n",
    "pl.title(\"Clusters\")\n",
    "pl.xlabel(\"Cluster1.length\")\n",
    "pl.ylabel(\"Cluster1.width\")\n",
    "pl.legend()\n",
    "\n",
    "\n",
    "# Aplicando el clustering jerárquico a nuestro dataset. Cluster X.\n",
    "jer1 = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
    "\n",
    "hc1 = cluster.AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "especieHC1 = hc1.fit_predict(Y)\n",
    "\n",
    "print(especieHC1)\n",
    "\n",
    "pl.scatter(X[especieHC1 == 0, 0], X[especieHC1 == 0, 1],s=100,c='red', label = \"Cluster 1\")\n",
    "pl.scatter(X[especieHC1 == 1, 0], X[especieHC1 == 1, 1],s=100,c='blue', label = \"Cluster 2\")\n",
    "pl.scatter(X[especieHC1 == 2, 0], X[especieHC1 == 2, 1],s=100,c='green', label = \"Cluster 3\")\n",
    "pl.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s=300, c=\"yellow\",marker=\"*\", label=\"Centroides\")\n",
    "pl.title(\"Clusters\")\n",
    "pl.xlabel(\"Clusters.length\")\n",
    "pl.ylabel(\"Clusters.width\")\n",
    "pl.legend()\n",
    "\n",
    "# Aplicando el clustering jerárquico a nuestro dataset. Cluster X.\n",
    "jer2 = sch.dendrogram(sch.linkage(Y, method = 'ward'))\n",
    "\n",
    "hc2 = cluster.AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "especieHC2 = hc1.fit_predict(Y)\n",
    "\n",
    "print(especieHC1)\n",
    "\n",
    "pl.scatter(Y[especieHC2 == 0, 0], Y[especieHC2 == 0, 1],s=100,c='red', label = \"Cluster 1\")\n",
    "pl.scatter(Y[especieHC2 == 1, 0], Y[especieHC2 == 1, 1],s=100,c='blue', label = \"Cluster 2\")\n",
    "pl.scatter(Y[especieHC2 == 2, 0], Y[especieHC2 == 2, 1],s=100,c='green', label = \"Cluster 3\")\n",
    "pl.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1], s=300, c=\"yellow\",marker=\"*\", label=\"Centroides\")\n",
    "pl.title(\"Clusters\")\n",
    "pl.xlabel(\"Clusters.length\")\n",
    "pl.ylabel(\"Clusters.width\")\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejercicio 5\n",
    "\n",
    "# metodo de la silueta\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('movies.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# clean data\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df = df[numerical_cols]\n",
    "df = df.drop('id',axis=1)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(df)\n",
    "\n",
    "# Get the silhouette score\n",
    "score = silhouette_score(df, kmeans.labels_, metric='euclidean')\n",
    "\n",
    "print('The silhouette score is:', score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ec50762aa24fb25566ff0abb0afbc5ab2bfb318ee4e8d478709981eeb95f91e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
